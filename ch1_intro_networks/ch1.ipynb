{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><span style=\"color:darkblue\">Quick start with PostgreSQL for Network Data Construction, Networkx for Analysis of Global Network Statistics, and Network Visualization </span><center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juan Estrada and Leonardo Sanchez-Aragon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\">1. Quick start with PostgreSQL and SQL Language </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "-  A database is a program which helps store data and provides functionality for **adding, modifying, and querying** that data.\n",
    "\n",
    "-  One of the most popular types of databases is the **relational database**. It stores each kind of data in a table where rows represent an item and columns represent properties of those items.\n",
    "\n",
    "-  Relational databases are particularly useful to form relationships between tables. This form of storage is more efficient than having to repeat rows to store all the information of related tables. See for example *authors_char, articles_char and articles_authors* tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tikz -s 600,600\n",
    "\\makeatletter\n",
    "\\tikzset{\n",
    "    database/.style={\n",
    "        path picture={\n",
    "            \\draw (0, 1.5*\\database@segmentheight) circle [x radius=\\database@radius,y radius=\\database@aspectratio*\\database@radius];\n",
    "            \\draw (-\\database@radius, 0.5*\\database@segmentheight) arc [start angle=180,end angle=360,x radius=\\database@radius, y radius=\\database@aspectratio*\\database@radius];\n",
    "            \\draw (-\\database@radius,-0.5*\\database@segmentheight) arc [start angle=180,end angle=360,x radius=\\database@radius, y radius=\\database@aspectratio*\\database@radius];\n",
    "            \\draw (-\\database@radius,1.5*\\database@segmentheight) -- ++(0,-3*\\database@segmentheight) arc [start angle=180,end angle=360,x radius=\\database@radius, y radius=\\database@aspectratio*\\database@radius] -- ++(0,3*\\database@segmentheight);\n",
    "        },\n",
    "        minimum width=2*\\database@radius + \\pgflinewidth,\n",
    "        minimum height=3*\\database@segmentheight + 2*\\database@aspectratio*\\database@radius + \\pgflinewidth,\n",
    "    },\n",
    "    database segment height/.store in=\\database@segmentheight,\n",
    "    database radius/.store in=\\database@radius,\n",
    "    database aspect ratio/.store in=\\database@aspectratio,\n",
    "    database segment height=0.1cm,\n",
    "    database radius=0.25cm,\n",
    "    database aspect ratio=0.35,\n",
    "}\n",
    "\\makeatother\n",
    "\n",
    "\\node[database,label=below:Database, database radius=1cm,database segment height=0.5cm] (database){};\n",
    "\n",
    "\\node[circle, draw, text centered, font = \\normalsize, align = center, minimum size=2cm] (dta) at (0:-3.5) {Data};\n",
    "\\path [draw] (database) to (dta);\n",
    "\n",
    "\\node[circle, draw, text centered, font = \\normalsize, align = center, minimum size=2cm] (res) at (0:3.5) {Results};\n",
    "\\path [draw] (database) to (res);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](publications_data.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "SQL is a language design entirely for accessing databases and it allows to:\n",
    "\n",
    "\n",
    "- Create tables.\n",
    "\n",
    "- Update and change data.\n",
    "\n",
    "- Query the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\">1.1 PostgreSQL </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "- Relational database management system (RDBMS).\n",
    "\n",
    "- One of the most popular RDBMS and increasing popularity during the last 6 years.\n",
    "\n",
    "- Open-source software in active development for over 30 years.\n",
    "\n",
    "- It has reputation for being a reliable, robust and secure data platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">RDBMS Advantages </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "- Creates a protective wrapper around your data and gives the ability to control modification.\n",
    "\n",
    "- Secures your data by enforcing access permission (particularly good for join projects).\n",
    "\n",
    "- Manages system performance which helps enter data and retrieve information in the most efficient ways possible.\n",
    "\n",
    "### <span style=\"color:darkblue\">Server/Client Model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tikz -s 500,500 -l fit\n",
    "\n",
    "\\tikzset{\n",
    "  comp/.style = {\n",
    "    minimum width  = 8cm,\n",
    "    minimum height = 4.5cm,\n",
    "    text width     = 8cm,\n",
    "    inner sep      = 0pt,\n",
    "    text           = green,\n",
    "    align          = center,\n",
    "    font           = \\Huge,\n",
    "    transform shape,\n",
    "    thick\n",
    "  },\n",
    "  monitor/.style = {draw = none, xscale = 18/16, yscale = 11/9},\n",
    "  display/.style = {shading = axis, left color = black!60, right color = black},\n",
    "  ut/.style      = {fill = gray}\n",
    "}\n",
    "\\tikzset{\n",
    "  computer/.pic = {\n",
    "    % screen (with border)\n",
    "    \\node(-m) [comp, pic actions, monitor]\n",
    "      {\\phantom{\\parbox{\\linewidth}{\\tikzpictext}}};\n",
    "    % display (without border)\n",
    "    \\node[comp, pic actions, display] {\\tikzpictext};\n",
    "    \\begin{scope}[x = (-m.east), y = (-m.north)]\n",
    "      % filling the lower part\n",
    "      \\path[pic actions, draw = none]\n",
    "        ([yshift=2\\pgflinewidth]-0.1,-1) -- (-0.1,-1.3) -- (-1,-1.3) --\n",
    "        (-1,-2.4) -- (1,-2.4) -- (1,-1.3) -- (0.1,-1.3) --\n",
    "        ([yshift=2\\pgflinewidth]0.1,-1);\n",
    "      % filling the border of the lower part\n",
    "      \\path[ut]\n",
    "        (-1,-2.4) rectangle (1,-1.3)\n",
    "        (-0.9,-1.4) -- (-0.7,-2.3) -- (0.7,-2.3) -- (0.9,-1.4) -- cycle;\n",
    "      % drawing the frame of the whole computer\n",
    "      \\path[pic actions, fill = none]\n",
    "        (-1,1) -- (-1,-1) -- (-0.1,-1) -- (-0.1,-1.3) -- (-1,-1.3) --\n",
    "        (-1,-2.4) coordinate(sw)coordinate[pos=0.5] (-b west) --\n",
    "        (1,-2.4) -- (1,-1.3) coordinate[pos=0.5] (-b east) --\n",
    "        (0.1,-1.3) -- (0.1,-1) -- (1,-1) -- (1,1) -- cycle;\n",
    "      % node around the whole computer\n",
    "      \\node(-c) [fit = (sw)(-m.north east), inner sep = 0pt] {};\n",
    "    \\end{scope}\n",
    "  }\n",
    "}\n",
    "\n",
    "\\makeatletter\n",
    "\\tikzset{\n",
    "    database/.style={\n",
    "        path picture={\n",
    "            \\draw (0, 1.5*\\database@segmentheight) circle [x radius=\\database@radius,y radius=\\database@aspectratio*\\database@radius];\n",
    "            \\draw (-\\database@radius, 0.5*\\database@segmentheight) arc [start angle=180,end angle=360,x radius=\\database@radius, y radius=\\database@aspectratio*\\database@radius];\n",
    "            \\draw (-\\database@radius,-0.5*\\database@segmentheight) arc [start angle=180,end angle=360,x radius=\\database@radius, y radius=\\database@aspectratio*\\database@radius];\n",
    "            \\draw (-\\database@radius,1.5*\\database@segmentheight) -- ++(0,-3*\\database@segmentheight) arc [start angle=180,end angle=360,x radius=\\database@radius, y radius=\\database@aspectratio*\\database@radius] -- ++(0,3*\\database@segmentheight);\n",
    "        },\n",
    "        minimum width=2*\\database@radius + \\pgflinewidth,\n",
    "        minimum height=3*\\database@segmentheight + 2*\\database@aspectratio*\\database@radius + \\pgflinewidth,\n",
    "    },\n",
    "    database segment height/.store in=\\database@segmentheight,\n",
    "    database radius/.store in=\\database@radius,\n",
    "    database aspect ratio/.store in=\\database@aspectratio,\n",
    "    database segment height=0.1cm,\n",
    "    database radius=0.25cm,\n",
    "    database aspect ratio=0.35,\n",
    "}\n",
    "\\makeatother\n",
    "\n",
    "\\node[database,label=below:Postgres Server, database radius=1cm,database segment height=0.5cm] (database){};\n",
    "\\pic[draw,fill = gray!30, scale = 0.25, pic text = {Client 2}](pc2) at (0:3.5){computer};\n",
    "\\node[circle](client2) at (0:2.5){};\n",
    "\\path [draw] (database) to (client2);\n",
    "\n",
    "\\pic[draw,fill = gray!30, scale = 0.25, pic text = {Client 1}](pc1) at (45:5){computer};\n",
    "\\node[circle](client1) at (45:3.5){};\n",
    "\\path [draw] (database) to (client1);\n",
    "\n",
    "\\pic[draw,fill = gray!30, scale = 0.25, pic text = {Client 3}](pc1) at (-45:5){computer};\n",
    "\\node[circle](client3) at (-45:4){};\n",
    "\\path [draw] (database) to (client3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "- In our case, we will be using an Amazon Web Service (AWS) Postgres Relational Database Service (RDS).\n",
    "\n",
    "- I will follow the steps of how to connect to the Postgres server from my local machine.\n",
    "\n",
    "- Once the connection is established, I will show how to create the relational database containing the data that I will be using to construct the networks.\n",
    "\n",
    "- The following process assumes that you have installed an interface client in your local machine, and you have already created an AWS Postgres server.\n",
    "\n",
    "- You can go back to presentation 2 for more information about cloud computing and how to set up the AWS Postgres server.\n",
    "\n",
    "- I will be using the graphical user interface called pgAdmin 4, here is a tutorial to install Postgres in your local machine https://www.postgresqltutorial.com/install-postgresql/ (it includes instructions for Windows, Linux and macOS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Process to Connect AWS Postgres Server to Local pgAdmin 4 </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "1. Go to the AWS instance containing the Postgres server and copy the Endpoint where you will be connecting to.\n",
    "\n",
    "2. In your pdAdmin 4 click on servers and then Add New Server.\n",
    "\n",
    "3. A new window asking for the server information will pop up. In the name section, you can use any name you want for the new AWS server.\n",
    "\n",
    "4. Click on to the connection page and in the Host name/address paste the Endpoint that you copied from the AWS instance. If the Endpoint includes the port at the end after a colon, erase it and write the port number in the Port space.\n",
    "\n",
    "5. Input the username and password that were created during the server set up process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Create the Database in the AWS Server </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "- To create the database and the tables inside, we will be using Structure Query Language (SQL).\n",
    "\n",
    "- The command to create the database is simple:\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "``` sql\n",
    "    CREATE DATABASE name\n",
    "      [ [ WITH ] [ OWNER [=] user_name ]\n",
    "            [ TEMPLATE [=] template ]\n",
    "            [ ENCODING [=] encoding ]\n",
    "            [ LC_COLLATE [=] lc_collate ]\n",
    "            [ LC_CTYPE [=] lc_ctype ]\n",
    "            [ TABLESPACE [=] tablespace ]\n",
    "            [ CONNECTION LIMIT [=] connlimit ] ]\n",
    "```\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "- I will use all the default options to create the database that we will be using in this course:\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "```sql\n",
    "    CREATE DATABASE publications\n",
    "```\n",
    "\n",
    "- The database is created and it comes with the default schemas ```public```, you can use that schema, change its name, or create different schemas for different parts of the database. For this example, I will change the Schema name for *table*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Create Tables in the Publications Database </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "The first step in process of inputting data into a database is to create a table. You can create different tables depending on the structure of the data that you are using. In this case, we provided you with the data structures and the tables' information in CSV format. We have 5 tables that are structured as illustrated in the **Entry Relationship Diagram** presented before. Therefore, we want the structure of the tables in the publications database to reflect the same structure.\n",
    "\n",
    "The 5 required tables can be constructed using the following SQL commands:\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "**1) Table with the relations between articles and authors:**\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "``` sql\n",
    "        CREATE TABLE public.articles_authors\n",
    "        (\n",
    "            articles_authors_id integer NOT NULL,\n",
    "            article integer NOT NULL,\n",
    "            year integer NOT NULL,\n",
    "            author integer NOT NULL,\n",
    "            editor_incharge boolean NOT NULL,\n",
    "            PRIMARY KEY (articles_authors_id)\n",
    "        );\n",
    "```\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "**2) Table with the characteristics of the articles (such as number of pages, journal, number of citations, etc.):**\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "``` sql\n",
    "        CREATE TABLE public.articles_char\n",
    "        (\n",
    "            articles_char_id integer NOT NULL,\n",
    "            article integer NOT NULL,\n",
    "            citation8 integer NOT NULL,\n",
    "            jelcode1 character(4),\n",
    "            jelcode2 character(4),\n",
    "            jelcode3 character(4),\n",
    "            jelcode4 character(4),\n",
    "            jelcode5 character(4),\n",
    "            jelcode6 character(4),\n",
    "            jelcode7 character(4),\n",
    "            keywords character(240),\n",
    "            \"references\" character(8910),\n",
    "            n_references integer NOT NULL,\n",
    "            n_authors integer NOT NULL,\n",
    "            title character(210) NOT NULL,\n",
    "            journal character(35) NOT NULL,\n",
    "            year integer NOT NULL,\n",
    "            issue integer NOT NULL,\n",
    "            start_page integer NOT NULL,\n",
    "            end_page integer NOT NULL,\n",
    "            abstract_scopus character(2030),\n",
    "            scival_scopus character(100),\n",
    "            pro_percentil_scopus numeric,\n",
    "            view_ref_scopus integer,\n",
    "            cit_scopus integer,\n",
    "            cit_impact_scopus numeric,\n",
    "            cit_by_scopus integer,\n",
    "            PRIMARY KEY (articles_char_id)\n",
    "        );\n",
    "```\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "**3) Table with the relations between articles and their editors in charge:**\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "```sql\n",
    "        CREATE TABLE public.articles_editors\n",
    "        (\n",
    "            articles_editors_id integer NOT NULL,\n",
    "            article integer NOT NULL,\n",
    "            year integer NOT NULL,\n",
    "            term integer NOT NULL,\n",
    "            incharge boolean NOT NULL,\n",
    "            editor_authorid integer,\n",
    "            PRIMARY KEY (articles_editors_id)\n",
    "        );\n",
    "```\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "**4) Table with the characteristics of the authors:**\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "```sql\n",
    "        CREATE TABLE public.authors_char\n",
    "        (\n",
    "            authors_char_id integer NOT NULL,\n",
    "            author integer NOT NULL,\n",
    "            male integer,\n",
    "            phd_inst character(35),\n",
    "            phd_year integer,\n",
    "            jel1_author character(1),\n",
    "            jel2_author character(1),\n",
    "            editor boolean NOT NULL,\n",
    "            PRIMARY KEY (authors_char_id)\n",
    "        );\n",
    "```\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "**5) Table with the job positions of the authors each year after they graduate from grad school:**\n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "```sql\n",
    "        CREATE TABLE public.authors_jobs\n",
    "        (\n",
    "            authors_jobs_id integer NOT NULL,\n",
    "            author integer NOT NULL,\n",
    "            year integer,\n",
    "            faculty character(80),\n",
    "            faculty_position character(25),\n",
    "            PRIMARY KEY (authors_jobs_id)\n",
    "        );\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Import Information From the Provided CSV Files </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "- Now that the tables are created inside the database, it is time to fill up the information for each table. To do that, I use the graphical user interface.\n",
    "\n",
    "- For each table, open the table's option by right clicking on it. Then, select Import/Export... Select Import and find the table that you want in your local machine.\n",
    "\n",
    "- Note that the CSV table must have the same name as the SQL table, it must have the same type for each column, and the strings must have a maximum number of characters given by the ```character(n)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\">1.2 SQL Language </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "- The SQL language is used to perform actions such as Create, Retrieve, Update and Delete on relational databases.\n",
    "\n",
    "- For that purpose, we use Queries. A Query is a set of instruction given to the database management system, which tells the Relational Database Management System (RDBMS) what information you would like to get from the database.\n",
    "\n",
    "- A SQL statement can be broken into three major component:\n",
    "\n",
    "        1. The SQL operation (SELECT)\n",
    "        2. The target (FROM)\n",
    "        3. The condition (WHERE, HAVING, etc)\n",
    "\n",
    "    \n",
    "\n",
    "- Only the SQL operation and target are required, the condition is optional. The most common operation in SQL, the query, makes use of the declarative SELECT statement. SELECT retrieves data from one or more tables, or expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Query for Coauthors' Edges Data </span> \n",
    "\n",
    "<font size=\"3\"> \n",
    "\n",
    "```sql\n",
    "        SELECT aa1.author AS source, aa2.author AS target\n",
    "        FROM tables.articles_authors aa1\n",
    "        LEFT JOIN tables.articles_authors AS aa2\n",
    "        USING(article)\n",
    "        WHERE aa1.year <= 2000 AND aa1.article = aa1.article AND aa1.author != aa2.author\n",
    "        ORDER BY source, target;\n",
    "```\n",
    "\n",
    "### <span style=\"color:darkblue\">Query for Advisor Edges Data </span> \n",
    "\n",
    "```sql\n",
    "        WITH s AS (\n",
    "        SELECT author, phd_inst, phd_year\n",
    "        FROM tables.authors_char\n",
    "        WHERE phd_inst IS NOT NULL AND phd_year IS NOT NULL)\n",
    "\n",
    "        SELECT s1.author AS source, s2.author AS targuet\n",
    "        --INTO adjacency_matrices.samephd\n",
    "        FROM s AS s1\n",
    "        LEFT JOIN s AS s2\n",
    "        USING (phd_inst)\n",
    "        WHERE s1.author != s2.author \n",
    "        AND s1.phd_year > s2.phd_year - 4 \n",
    "        AND s1.phd_year < s2.phd_year + 4\n",
    "        AND s1.author IN (SELECT DISTINCT author FROM tables.articles_authors WHERE year <= 2000)\n",
    "        AND s2.author IN (SELECT DISTINCT author FROM tables.articles_authors WHERE year <= 2000)\n",
    "        ORDER BY s1.author, s2.author;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Creating Edges Data Using ```psycopg2``` in Python </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import networkx as nx\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(net, year, articles, con):\n",
    "    \n",
    "    coauthors_query = (\"SELECT aa1.author AS source, aa2.author AS target \\\n",
    "                       FROM tables.articles_authors aa1 \\\n",
    "                       LEFT JOIN tables.articles_authors AS aa2 \\\n",
    "                       USING(article) \\\n",
    "                       WHERE aa1.year <= '{}' AND aa1.article = aa1.article AND aa1.author != aa2.author \\\n",
    "                       ORDER BY source, target\").format(year)\n",
    "\n",
    "    samephd_query = (\"WITH s AS (SELECT author, phd_inst, phd_year \\\n",
    "                       FROM tables.authors_char \\\n",
    "                       WHERE phd_inst IS NOT NULL AND phd_year IS NOT NULL) \\\n",
    "                       SELECT s1.author AS source, s2.author AS target \\\n",
    "                       FROM s AS s1 LEFT JOIN s AS s2 \\\n",
    "                       USING (phd_inst) \\\n",
    "                       WHERE s1.author != s2.author AND s1.phd_year > s2.phd_year - 4 AND s1.phd_year < s2.phd_year + 4 \\\n",
    "                       AND s1.author IN (SELECT DISTINCT author FROM tables.articles_authors WHERE year <= '{}') \\\n",
    "                       AND s2.author IN (SELECT DISTINCT author FROM tables.articles_authors WHERE year <= '{}') \\\n",
    "                       ORDER BY s1.author, s2.author\").format(year, year)\n",
    "\n",
    "                        \n",
    "    ph = \"author\" if articles == False else \"article\"\n",
    "                \n",
    "    nodes_query = (\"SELECT DISTINCT \" + ph + \"\\\n",
    "                  FROM tables.articles_authors \\\n",
    "                  WHERE year <= '{}' \\\n",
    "                  ORDER BY \"+ ph + \";\").format(year)\n",
    "    \n",
    "    if net == 'coauthor':\n",
    "        query_type = coauthors_query\n",
    "    else:\n",
    "        query_type = samephd_query\n",
    "    \n",
    "    articles_query = (\"WITH s AS(\"+ query_type + \") \\\n",
    "                    SELECT DISTINCT a1.article AS source, a2.article AS target \\\n",
    "                    FROM s \\\n",
    "                    LEFT JOIN tables.articles_authors AS a1 \\\n",
    "                    ON s.source = a1.author \\\n",
    "                    LEFT JOIN tables.articles_authors AS a2 \\\n",
    "                    ON s.target = a2.author \\\n",
    "                    WHERE a1.article != a2.article \\\n",
    "                    AND a1.year <= '{}' AND a2.year <= '{}' \\\n",
    "                    ORDER BY a1.article, a2.article;\").format(year, year)\n",
    "\n",
    "    edges_ca = sqlio.read_sql_query(query_type+\";\", con) if articles == False else sqlio.read_sql_query(articles_query, con)\n",
    "    nodes_ca = sqlio.read_sql_query(nodes_query, con)\n",
    "    \n",
    "    return [nodes_ca, edges_ca] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psycopg2.connect(\n",
    "    host = '3.131.204.20',\n",
    "    database = 'g3sls',\n",
    "    user = 'jjestra',\n",
    "    password  = 'JJEslt14*')\n",
    "\n",
    "results = create_graph('coauthor', 2000, False, con)\n",
    "nodes = results[0]\n",
    "edges = results[1]\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\">2. Basic Terms and Notation in Networks Using ```networkx``` </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "*Disclaimer:* Many of the concept in this notes are based on a presentation by Brian Graham in Annweiler-Germany 2019.\n",
    "\n",
    "\n",
    "NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. The basic components of the library are:\n",
    "\n",
    "- **Graph Creation:** this includes different ways to generate non-random (trees, cycles, full, etc) or random (Erdos_Renyi, Newman-Watts-Strogatz, etc) graphs.\n",
    "- **Algorithms:** includes functions to calculate statistics of the network such as centrality, clustering, components, communities, etc.\n",
    "- **Reading and writing graphs:** read/write graphs from/to other data types such as pandas, numpy, scipy, etc.\n",
    "- **Basic visualization**\n",
    "- Explore more here: https://networkx.org/documentation/stable/index.html\n",
    "\n",
    "Note that there are other packages to analyze networks that may have a better performance in terms of time to calculate commonly used algorithms. Also, different packages include different algorithms so you should take that into consideration. Here is an analysis of the performance of different network packages: https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/#fn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Basic Terms </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "An undirected graph $G(N,E)$ consists of a set of nodes $N={1,…,N}$ and a a list of unordered pairs of nodes called edges $E=\\{\\{i,j\\},\\{k,l\\},\\dots\\}$ for all $i,j,k,l \\in N$\n",
    "\n",
    "### <span style=\"color:darkblue\">Reading the data into Networkx </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(np.squeeze(nodes.values).tolist())\n",
    "\n",
    "tuples = [tuple(x) for x in edges.to_numpy()]\n",
    "G.add_edges_from(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.nodes())[0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.edges())[0:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Network Visualization Using Python </span>\n",
    "\n",
    "The following visualization will be created the ```plotly``` Python library. It is an interactive plotting library that support interactive web-based visualizations built on top of the JavaScript library plotly.js. This type of network visualization is particularly good when it is used along with Jupyter Notebooks to be able to display the stand alone HTML files.\n",
    "\n",
    "For the next visualization and the study of the network statistics, I will remove the isolated nodes (this is optional but the network graph looks more clear this way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "***Step 1:*** add the position attribute to the nodes using ```networkx```. To create a position, I will use the random layout of the ```netwokrx``` package.\n",
    "\n",
    "Other options for layouts:\n",
    "\n",
    "- circular_layout\n",
    "\n",
    "- shell_layout\n",
    "\n",
    "- spring_layout\n",
    "\n",
    "- spectral_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G, scale = 20, iterations = 15)\n",
    "nx.set_node_attributes(G, pos, 'pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "**Step 2:** Use the positions created in the previous step along with the ```Scatter``` function of ```plotly``` to create the objects with the edges and nodes positioned in a 2 dimensional space. There are other options that are used from the ```Scatter``` function:\n",
    "\n",
    "- line: create lines of with 0.5 and color gray ('#888')\n",
    "\n",
    "- mode: draws lines for the edges and markers for the nodes\n",
    "\n",
    "- marker: defines nodes characteristics such as color, color scale, title of the color scale and position\n",
    "\n",
    "Some options for colors are:\n",
    "\n",
    "- 'Greys'\n",
    "- 'YlGnBu'\n",
    "- 'Greens'\n",
    "- 'YlOrRd'\n",
    "- 'Bluered'\n",
    "- 'RdBu'\n",
    "- 'Reds'\n",
    "- 'Blues'\n",
    "- 'Picnic'\n",
    "- 'Rainbow'\n",
    "- 'Portland'\n",
    "- 'Jet'\n",
    "- 'Hot'\n",
    "- 'Blackbody'\n",
    "- 'Earth'\n",
    "- 'Electric'\n",
    "- 'Viridis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Add edges as disconnected lines in 2d space\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = G.nodes[edge[0]]['pos']\n",
    "    x1, y1 = G.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "    \n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in G.nodes():\n",
    "    x, y = G.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "**Step 3:** create the scale that the graph will use. In this case, we will be working with the number of connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append('# of connections: '+str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>Coauthos Network graph made with Python',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"Created by Juan Estrada\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Adjacency Matrix </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "A graph is conveniently represented by its adjacency matrix $W=[Wij]$ where\n",
    "\n",
    "$$W_{ij} = \\begin{cases}\n",
    "  1 & \\text{if } \\{i,j\\} \\in E \\\\\n",
    "  0 & \\text{otherwise}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\">3. Global Network Statistics </span>\n",
    "\n",
    "### <span style=\"color:darkblue\">Degree Sequence - Degree Distribution </span>\n",
    "\n",
    "<font size=\"4\"> \n",
    "\n",
    "Some classical research take the degree distribution as the primary object of interest, and some datasets report agent degrees with no other network information.\n",
    "\n",
    "- The total number of links belonging to agent $i$ , or her degree is $W_{i+} = \\sum_{j} W_{ij}$\n",
    "\n",
    "- The degree sequence of a network is $W_{+} = (W_{1+},…,W_{N+})^{⊤}$\n",
    "\n",
    "- The degree distribution gives the frequency of each possible agent-level degree count $\\{0,1,\\dots,N\\}$  in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.degree())[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)  \n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(deg, cnt, width=0.80, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Degree Sequence - Degree Distribution </span>\n",
    "\n",
    "<font size=\"4\">\n",
    "\n",
    "- Dyads are either link or unliked. The density of a network equals the frequency with which any randomly drawn dyad is linked:\n",
    "\n",
    "$$\\hat{\\rho}_{N}={N \\choose 2}^{-1} \\sum_{i=1}^{N}\\sum_{j<i} W_{ij}$$\n",
    "\n",
    "- Average degree:\n",
    "\n",
    "$$\\hat{\\lambda}_{N} = (N-1)\\hat{\\rho}_{N}$$\n",
    "\n",
    "- Low density and skewed degree distributions (with fat tails) are common features of real world social networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Density of the Coauthors Network is '+str(round(nx.density(G), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Average Degree of the Coauthors Network is '+ str(round(sum(degree_sequence)/len(degree_sequence),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Degree Sequence - Degree Distribution </span>\n",
    "\n",
    "<font size=\"4\">\n",
    "\n",
    "- **Paths of length two:** if $i$ and $j$ share the common friend $k$, then a length two path from $i$ to $j$ is given by $i \\rightarrow k \\rightarrow j$. The elements $ij$ th of $W^{2}$ gives the number of paths of length two from agent $i$ to agent $j$.\n",
    "\n",
    "- **Paths of length three:** The elements $ij$ th of $W^{3}$ gives the number of paths of length two from agent  $i$ to agent $j$.\n",
    "\n",
    "- If both $i$ and $j$ are connected to $k$ as well as to each other, then the $i,j,k$ triad is transitive (**triangle**).\n",
    "\n",
    "- The $i$ th element of $W^{3}$ gives the number of triangles to which $i$ belongs (with $i \\rightarrow j \\rightarrow k$ and $i \\rightarrow k \\rightarrow j$ counted separately).\n",
    "\n",
    "- **Paths of length $k$:** The elements $ij$ th of $W^{k}$ gives the number of paths of length two from agent $i$ to agent $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.all_simple_paths(G, 17, 107))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "- **Distance:** The distance between agents $i$ and $j$ equals the minimum length path connecting them:\n",
    "\n",
    "$$M_{ij} = \\min_{k}\\{k: W_{ij}^{(k)}>0\\}$$\n",
    "\n",
    "- If the network consists of a single, giant, connected component, we can compute average path length as:\n",
    "\n",
    "$$\\bar{M} = {N \\choose 2}^{-1} \\sum_{i=1}^{N}\\sum_{j<i} M_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.shortest_path_length(G))[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gc_average_shortest_path_length(G, isolated = True):\n",
    "    \n",
    "    G.remove_nodes_from(list(nx.isolates(G))) if isolated == True  else G\n",
    "    mean_gc = []\n",
    "    sizes = []\n",
    "    for C in (G.subgraph(c).copy() for c in nx.connected_components(G)):\n",
    "        mean_gc.append(nx.average_shortest_path_length(C))\n",
    "        sizes.append(nx.number_of_nodes(C))\n",
    "        \n",
    "    return np.sum(np.multiply(mean_gc,sizes))/np.sum(sizes)\n",
    "\n",
    "round(gc_average_shortest_path_length(G),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "- **Diameter:** largest distance between two agents in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = []\n",
    "for C in (G.subgraph(c).copy() for c in nx.connected_components(G)):\n",
    "        diameter.append(nx.diameter(C))\n",
    "\n",
    "max(diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">Small World Problem </span>\n",
    "\n",
    "Around 0.5% of nodes are directly connected in the coauthors network but the diameter is only 4. why do we see sparsity and low diameter together? Milgram (1967).\n",
    "\n",
    "### <span style=\"color:darkblue\">Small World Problem </span>\n",
    "\n",
    "The transitivity index (TI) is given by\n",
    "\n",
    "$$ TI = 3 \\times \\frac{\\text{triangles}}{\\text{triads}}$$\n",
    "\n",
    "In random graphs TI should be close to network density. However, **in practice TI often substantially exceeds network density**, in other words links are more clustered than would be expected under the homogenous random graph null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(nx.transitivity(G),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The TI in the Coauthors network ('+str(round(nx.transitivity(G),3))+') substantially exceeds the network density ('+str(round(nx.density(G), 3))+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Multilayer Network Statistics and Visualization</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer:* Many of the concept in this notes are based on a presentation by Brian Graham in Annweiler-Germany 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\">1. Monolayer </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">1.1 Important Nodes </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> \n",
    "\n",
    "- The objective is to learn methods to identify nodes that are important in a network. \n",
    "    \n",
    "    \n",
    "- There are different statistics that can provide information about the importance of a node from different perspectives.\n",
    "    \n",
    "    \n",
    "- Finding important nodes can help to answer questions such as:\n",
    "    \n",
    "    \n",
    "- Removal of what node would reduce disease transmission the most?\n",
    "    \n",
    "    \n",
    "- What nodes should companies target to incentivize technology adoption?\n",
    "    \n",
    "    \n",
    "- Can sectoral idiosyncratic shocks lead to aggregate fluctuations?\n",
    "    \n",
    "    \n",
    "- How do agent-specific shocks percolate through a network to generate social multipliers?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/data' # Change this path for the location of empirical_multilayer_cloud/data in your local machine\n",
    "\n",
    "import psycopg2\n",
    "import pandas.io.sql as sqlio\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "import itertools as it\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(net, year, articles, con):\n",
    "    \n",
    "    coauthors_query = (\"SELECT aa1.author AS source, aa2.author AS target \\\n",
    "                       FROM tables.articles_authors aa1 \\\n",
    "                       LEFT JOIN tables.articles_authors AS aa2 \\\n",
    "                       USING(article) \\\n",
    "                       WHERE aa1.year <= '{}' AND aa1.article = aa1.article AND aa1.author != aa2.author \\\n",
    "                       ORDER BY source, target\").format(year)\n",
    "\n",
    "    samephd_query = (\"WITH s AS (SELECT author, phd_inst, phd_year \\\n",
    "                       FROM tables.authors_char \\\n",
    "                       WHERE phd_inst IS NOT NULL AND phd_year IS NOT NULL) \\\n",
    "                       SELECT s1.author AS source, s2.author AS target \\\n",
    "                       FROM s AS s1 LEFT JOIN s AS s2 \\\n",
    "                       USING (phd_inst) \\\n",
    "                       WHERE s1.author != s2.author AND s1.phd_year > s2.phd_year - 4 AND s1.phd_year < s2.phd_year + 4 \\\n",
    "                       AND s1.author IN (SELECT DISTINCT author FROM tables.articles_authors WHERE year <= '{}') \\\n",
    "                       AND s2.author IN (SELECT DISTINCT author FROM tables.articles_authors WHERE year <= '{}') \\\n",
    "                       ORDER BY s1.author, s2.author\").format(year, year)\n",
    "                        \n",
    "    ph = \"author\" if articles == False else \"article\"\n",
    "                \n",
    "    nodes_query = (\"SELECT DISTINCT \" + ph + \"\\\n",
    "                  FROM tables.articles_authors \\\n",
    "                  WHERE year <= '{}' \\\n",
    "                  ORDER BY \"+ ph + \";\").format(year)\n",
    "    \n",
    "    if net == 'coauthor':\n",
    "        query_type = coauthors_query\n",
    "    else:\n",
    "        query_type = samephd_query\n",
    "    \n",
    "    articles_query = (\"WITH s AS(\"+ query_type + \") \\\n",
    "                    SELECT DISTINCT a1.article AS source, a2.article AS target \\\n",
    "                    FROM s \\\n",
    "                    LEFT JOIN tables.articles_authors AS a1 \\\n",
    "                    ON s.source = a1.author \\\n",
    "                    LEFT JOIN tables.articles_authors AS a2 \\\n",
    "                    ON s.target = a2.author \\\n",
    "                    WHERE a1.article != a2.article \\\n",
    "                    AND a1.year <= '{}' AND a2.year <= '{}' \\\n",
    "                    ORDER BY a1.article, a2.article;\").format(year, year)\n",
    "\n",
    "    edges_ca = sqlio.read_sql_query(query_type+\";\", con) if articles == False else sqlio.read_sql_query(articles_query, con)\n",
    "    nodes_ca = sqlio.read_sql_query(nodes_query, con)\n",
    "    \n",
    "    return [nodes_ca, edges_ca]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psycopg2.connect(\n",
    "    host = '3.131.204.20',\n",
    "    database = 'g3sls',\n",
    "    user = 'jjestra',\n",
    "    password  = 'JJEslt14*')\n",
    "\n",
    "results = create_graph('coauthor', 2002, False, con)\n",
    "nodes = results[0]\n",
    "edges = results[1]\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(np.squeeze(nodes.values).tolist())\n",
    "\n",
    "tuples = [tuple(x) for x in edges.to_numpy()]\n",
    "G.add_edges_from(tuples)\n",
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">1.2 Degree Centrality </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "$$\\frac{W_{i+}}{|\\mathbf{W}|-1}$$\n",
    "    \n",
    "\n",
    "Where $W_{i+}=\\sum_{j} W_{i j}$ is the degree of individual $i$ and $|\\mathbf{W}|$ is the total number of nodes in $\\mathbf{W}$.\n",
    "    \n",
    "    \n",
    "- This measure of centrality captures the idea that nodes with more connections a more important in the network just because they are more prestigious or popular. \n",
    "    \n",
    "    \n",
    "- In the coauthors network, it is intuitive to think that more productive and prestigious scholars would tend to have more coauthors.\n",
    "    \n",
    "    \n",
    "- We can also think about influencers in social network platforms, disease super spreaders, airport hubs, or important sectors in the supply chain.\n",
    "    \n",
    "    \n",
    "- This definition can be extended to the directed graphs where you can define \n",
    "    \n",
    "    \n",
    "    \n",
    "- In-degree: $W_{+i}=\\sum_{j} W_{j i}$ (column sums of $\\mathbf{W}$). **Represents:** prestige, popularity, buyers\n",
    "\n",
    "    \n",
    "- Out-degree: $W_{i+}=\\sum_{j} W_{i j}$ (row sums of $\\mathbf{W}$). **Represents:** extroverts, diffusers, suppliers\n",
    "<font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(it.islice(dc.items(),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dc = max(dc.values())\n",
    "max_dck = [x for x, y in dc.items() if y == max_dc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The maximum degree centrality is '+str(round(max_dc,2))+' corresponding to nodes '+str(max_dck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = dict(G.degree())\n",
    "max_d = max(degree.values())\n",
    "max_dn = [x for x, y in degree.items() if y == max_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The maximum degree in the network is '+str(max_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "⚠️**Empirical Fining:**\n",
    "    \n",
    "    \n",
    "- Authors 29 and 1965 are connected with 8 other scholars each, which as a fraction of a total of 1088 nodes, represents a degree centrality of approximately 0.01. We can access the information of the authors and potentially find out who they are.\n",
    "    \n",
    "    \n",
    "- From the information it is possible to infer that the scholar represented by the numbers 29 and 1963 are <font color=\"darkgreen\">Alberto Alesina</font> and <font color = \"darkgreen\">Thomas M. Humphrey</font> respectively.\n",
    "\n",
    "<font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_char = pd.read_csv(path + '/sql/authors_char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_char[(authors_char.author == max_dck[0]) | (authors_char.author == max_dck[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "**Limitations:**\n",
    "    \n",
    "    \n",
    "- This definition does not consider indirect connections.\n",
    "    \n",
    "    \n",
    "- Imagine scholars 29 and 1965 who have 8 connections each. But let's say that every neighbor of node 29 has only 1 connection, while the neighbors of 1965 have 8 connections each.\n",
    "    \n",
    "    \n",
    "- Scholar 29 would have **8 direct and 8 indirect** connections while 1965 would have **8 direct and 64 indirect** connections. \n",
    "    \n",
    "    \n",
    "- What node is then more important?\n",
    "    \n",
    "    \n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">1.3 Eigenvalue Centrality </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "- Proposed by Bonacich (1972) and Katz (1953).\n",
    "    \n",
    "\n",
    "- Recursively computes the centrality for a node based on the centrality of its neighbors.\n",
    "\n",
    "    \n",
    "    \n",
    "$$\\begin{array}{l}\n",
    "c_{i}^{\\mathrm{EC}}(\\mathbf{W}, \\phi)=\\phi \\sum_{j} c_{j}^{\\mathrm{EC}}(\\mathbf{W}, \\phi) W_{j i} \\\\\n",
    "\\mathbf{c}^{\\mathrm{EC}}(\\mathbf{W}, \\phi)=\\phi \\mathbf{c}^{\\mathrm{EC}}(\\mathbf{W}, \\phi) \\mathbf{W}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "    \n",
    "- Where $c_{i}^{\\mathrm{EC}}$ is the eigenvalue centrality of individual $i$ and $\\mathbf{c}^{\\mathrm{EC}}$ is a $n \\times 1$ vector of eigenvalue centrality.\n",
    "    \n",
    "    \n",
    "- The eigenvalue centrality is defined for $\\phi=1 / \\lambda_{max}$ where $\\lambda_{max}$ is the maximum eigenvalue of $\\mathbf{W}$, which guarantees a solution of $\\mathrm{c}^{\\mathrm{EC}}(\\mathbf{W}, \\phi)\\left[\\frac{1}{\\phi} I_{N}-\\mathrm{D}\\right]=0$  given by the left eigenvector associated with the largest eigenvalue of $\\mathbf{W}$.\n",
    "    \n",
    "    \n",
    "- If the normalization is done by $\\mathbf{D} = \\operatorname{diag}\\left\\{\\max \\left(1, W_{1+}\\right), \\ldots, \\max \\left(1, W_{N+}\\right)\\right\\}^{-1} \\times \\mathrm{W}$, then $\\mathbf{D}$ is row stochastic and the eigenvector centrality correspond to a stationary vector of a Markov chain.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = nx.eigenvector_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(it.islice(ec.items(),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ec = max(ec.values())\n",
    "max_eck = [x for x, y in ec.items() if y == max_ec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The maximum degree centrality is '+str(round(max_ec,4))+' corresponding to nodes '+str(max_eck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This node has '+str(degree[1000])+' connections and '+str(round(dc[1000],2))+' degree centrlity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eigenvalue centrality for nodes 29 and 1965 '+str(round(ec[29],4)) +' and '+str(round(ec[1965],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_char[(authors_char.author == max_eck[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_df = pd.DataFrame(list(ec.items()),columns = ['scholar','ec']) \n",
    "ec_df.sort_values(by = ['ec'], ascending=False).head()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "⚠️**Empirical Fining:**\n",
    "\n",
    "Based on the Eigenvalue Centrality, scholars 1000 and 1332 are the most important in the network. The characteristics of this scholar together with his publication record, make possible to infer that <font color=\"darkgreen\">Joshua Angrist</font> is the author with the highest eigenvalue centrality, followed by <font color=\"darkgreen\">Michael Kremer</font>.\n",
    "    \n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">1.4 Katz Centrality and the Social Multiplier </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "- Computes the centrality for a node based on the centrality of its neighbors. It is a generalization of the eigenvector centrality. \n",
    "    \n",
    "\n",
    "$$c_{i}^{K}(\\alpha,\\beta, \\mathbf{W})=\\alpha + \\beta \\sum_{j \\neq i} W_{i j} c_{j}^{K}\\text{.}$$\n",
    "    \n",
    "    \n",
    "- The parameter $\\alpha$ controls the initial centrality and $\\beta<1/\\lambda_{\\text{max}}$.\n",
    "\n",
    "    \n",
    "- The relative influence of a node is given by the number of the immediate neighbors (first degree nodes) and also all other nodes in the network that connect to the node under consideration through these immediate neighbors.\n",
    "    \n",
    "    \n",
    "- The parameter $\\beta$ penalizes the distant connections. In matrix form the previous equation can be written as:\n",
    "    \n",
    "    \n",
    "$$\\mathbf{c}^{K}(\\alpha,\\beta, \\mathbf{W})=\\alpha\\iota_{n}^{\\prime}(\\mathbf{I}-\\beta\\mathbf{W})^{-1}\\text{.}$$\n",
    "    \n",
    "    \n",
    "\n",
    "- Where $(\\mathbf{I}-\\beta\\mathbf{W})^{-1} = \\sum_{k=0}^{\\infty} \\beta^{k} \\mathbf{W}^{k}$ for $\\beta<1/\\lambda_{\\text{max}}$ represents the attenuated effects of distant nodes. \n",
    "    \n",
    "    \n",
    "    \n",
    "**Relation with the Social Multiplier of a Quadratic complementarity Game (Jackson and Zenou, 2015).**\n",
    "\n",
    "    \n",
    "- Let $y_{i}$ be a continuously-valued action chosen by agent $i = 1, \\dots, n$, where $\\mathbf{y}$ is the associated vector of actions.\n",
    "    \n",
    "    \n",
    "- Agents are connected by a row normalized adjacency matrix $\\mathbf{D}$, so that $\\mathbf{D}_{i}\\mathbf{y} = \\sum_{j \\neq i} G_{i j} y_{j}$ represent the average actions of individual $i$'s connections \n",
    "  \n",
    "    \n",
    "- The payoff function includes complementarities: $u_{i}(\\mathbf{y} ; \\mathbf{W}) = \\left(\\alpha_{0}+U_{i}\\right) y_{i}-\\frac{1}{2} y_{i}^{2}+\\beta_{0}\\mathbf{D}_{i}\\mathbf{y} y_{i}$\n",
    "\n",
    "    \n",
    "- Where $U_{i}$ represents heterogeneity in payoffs. The best response function is given by\n",
    "   \n",
    "    \n",
    "$$y_{i}=\\alpha_{0}+\\beta_{0} \\sum_{j \\neq i} D_{i j} y_{j}+U_{i}$$\n",
    "\n",
    "    \n",
    "    \n",
    "- Which is equivalent to the definition of the Katz centrality plus a random component $U_{i}$. The matrix form is given by:\n",
    "    \n",
    "    \n",
    "$$\\mathbf{Y}=\\alpha_{0}\\left(I_{N}-\\beta_{0} \\mathbf{D}\\right)^{-1} \\iota_{N}+\\left(I_{N}-\\beta_{0} \\mathbf{D}\\right)^{-1} \\mathrm{U}$$\n",
    "    \n",
    "- So that a policy increasing agent $i$ value of $U_{i}$ will be amplified by a factor corresponding to the $i$th row of $\\iota\\left(I_{N}-\\beta_{0} \\mathbf{D}\\right)^{-1}$ on the equilibrium action vector.\n",
    "    \n",
    "    \n",
    "- The social multiplier is heterogeneous across agents, and depends on their centrality: $\\mathbf{c}^{SM}(\\mathbf{D}, \\beta)=\\iota_{n}^{\\prime}\\left(I_{N}-\\beta \\mathbf{G}\\right)^{-1}$\n",
    "    \n",
    "    \n",
    "- If the parameter $\\alpha$ in the Katz centrality equals one, and it is calculated using the normalized matrix $\\mathbf{D}$, then the social multiplier and the Katz centrality measures coincide. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.to_numpy_array(G)\n",
    "sum_rows = W.sum(axis=1)\n",
    "D = W / sum_rows[:, np.newaxis]\n",
    "Id = np.identity(D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc_list = np.linalg.solve(Id- 0.570*D, Id).sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc = {list(G.nodes)[i]: smc_list[i] for i in range(len(G))} \n",
    "max_smc = max(smc.values())\n",
    "max_smck = [x for x, y in smc.items() if y == max_smc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The maximum Social Multiplier centrality is '+str(round(max_smc,2))+' corresponding to nodes '+str(max_smck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Social Multiplier centrality of scholar 1000 is '+str(round(smc[1000],2))+' and for scholar 1965 it is '+str(round(smc[1965],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc_df = pd.DataFrame(list(smc.items()),columns = ['scholar','smc']) \n",
    "smc_df.sort_values(by = ['smc'], ascending=False).head()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"4\">\n",
    "\n",
    "⚠️**Empirical Finding:**\n",
    "    \n",
    "Based on the Social Multiplier Centrality, scholars 29 and 1789 are the most important nodes in the network. As we saw, node 29 corresponds with <font color=\"darkgreen\">Alberto Alesina</font>, while node 1789 is <font color=\"darkgreen\">Steven D. Levitt</font>.\n",
    "    \n",
    " <font size=\"4\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">1.5 Betweenness Centrality</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "Betweenness centrality of a node $i$ is the sum of the fraction of all-pairs shortest paths that pass through v:\n",
    "\n",
    "$$c_{BC}(i)=\\sum_{s, t \\in V} \\frac{\\sigma(s, t \\mid i)}{\\sigma(s, t)}$$\n",
    "\n",
    "Where $V$ is the set of nodes, $\\sigma(s, t)$ is the number of shortest $(s, t)$-paths, and $\\sigma(s, t \\mid i)$ is the number of those paths passing through some node $i$ other than $s$, $t$. If $s = t$, then $\\sigma(s, t) = 1$, and if $i \\in {s, t}$, then $\\sigma(s, t|v) = 0$.\n",
    "    \n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = nx.betweenness_centrality(G)\n",
    "max_bc = max(bc.values())\n",
    "max_bck = [x for x, y in bc.items() if y == max_bc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The maximum Social Multiplier centrality is '+str(round(max_bc,4))+' corresponding to nodes '+str(max_bck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df = pd.DataFrame(list(bc.items()),columns = ['scholar','bc']) \n",
    "bc_df.sort_values(by = ['bc'], ascending=False).head()[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "⚠️**Empirical Finding:**\n",
    "    \n",
    "In this measure the <font color=\"darkgreen\">Daron Acemoglu</font> (node 336) leads followed by <font color=\"darkgreen\">Simon Johnson</font> (node 1748).\n",
    "    \n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:darkblue\">2. Multilayer Networks </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">2.1 Basic Definitions </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "A multilayer network is a pair $\\mathcal{M}=(\\mathcal{G}, \\mathcal{C})$, where\n",
    "    \n",
    "    \n",
    "- $\\mathcal{G}=\\left\\{G_{m} ; m \\in\\{1, \\ldots, M\\}\\right\\}$ is a set of graphs $G_{m}=\\left(V_{m}, E_{m}\\right)$.\n",
    "    \n",
    "\n",
    "- Each graph $m$ is formed by a set of nodes and a set of edges represented by $V_{m}$ and $E_{m}$ respectively.\n",
    "\n",
    "\n",
    "- The graphs in $\\mathcal{G}$ are allowed to be directed or undirected, weighted or unweighted but are assumed to not have self cycles.\n",
    "    \n",
    "\n",
    "- Let $\\mathcal{C}$ be the set of interconnections between nodes of different layers $G_m$ and $G_s$ with $m \\neq s$\n",
    "\n",
    "\n",
    "$$\\mathcal{C}=\\left\\{E_{m, s} \\subseteq V_{m} \\times V_{s} ; m, s \\in\\{1, \\ldots, M\\}, m \\neq s\\right\\}\\text{.}$$\n",
    "    \n",
    "\n",
    "- The set of edges $E_m$ are known as **intralayer connections** and the edges in $\\mathcal{C}$ are known as **Interlayer connections**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">2.2 Network Visualization Using R using the articles networks</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "The following visualizations use the R package ```igraph```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "options(warn=-1)\n",
    "library('igraph')\n",
    "library('haven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "setwd('/home/data/stata') # Change this path for the location of .../data/stata in your local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "1) Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "edges.co <- read_dta('edges.dta')\n",
    "edges.al <- read_dta('edges0.dta')\n",
    "\n",
    "nodes <- read_dta('articles.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "2) Create undirected networks based on the edge lists for the coauthors (```edges```) and alumni (```edges0```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "coauthors <- graph_from_data_frame(d=edges.co, vertices=nodes, directed=F)\n",
    "alumni <- graph_from_data_frame(d=edges.al, vertices=nodes, directed=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "alumni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "3) Drop isolated nodes from the coauthors and alumni networks to improve the aesthetics of the network visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "isolated.co <- which(degree(coauthors)==0)\n",
    "isolated.al <- which(degree(alumni)==0)\n",
    "\n",
    "coauthors <- delete.vertices(coauthors, isolated.co)\n",
    "alumni <- delete.vertices(alumni, isolated.al)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "4) Define different colors for each journal where the paper was publish and include appropriate layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "colors <- c(\"tomato\", \"darkblue\", \"chartreuse3\", \"gold\")\n",
    "V(coauthors)$color <- colors[V(coauthors)$journal]\n",
    "V(alumni)$color <- colors[V(alumni)$journal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "l <- layout_with_fr(alumni)\n",
    "l <- norm_coords(l, ymin=-1, ymax=1, xmin=-1, xmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "5) Create a side-by-side plot with the two complete networks dividing nodes by journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "options(repr.plot.width=20, repr.plot.height=20)\n",
    "\n",
    "par(mfrow=c(1,2), mar=c(0, 0, 0, 0), oma=c(0, 0, 0, 0))\n",
    "plot(coauthors,vertex.label=NA, vertex.size= 2, layout = layout_with_mds(coauthors))\n",
    "title(\"Coauthors Network\", line = -15) \n",
    "plot(alumni,vertex.label=NA, vertex.size= 2, layout = l)\n",
    "title(\"Alumni Network\", line = -15)\n",
    "\n",
    "legend(-2,-1.5, legend = c(\"AER\",\"ECA\", \"JPE\", \"QJE\"),  lwd = 5,xpd= \"NA\", col=colors, horiz = T,cex = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "**Plot different graphs for each journal for the coauthors and alumni networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "1) Create a function to keep only nodes for one journal at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "exclude_nodes <- function(original, n1,n2,n3){\n",
    "    new.net <- delete.vertices(original, V(original)[V(original)$journal ==n1 | V(original)$journal ==n2 | V(original)$journal ==n3])\n",
    "    new.net.iso <- which(degree(new.net)==0)\n",
    "    new.net <- delete.vertices(new.net, new.net.iso)\n",
    "    V(new.net)$size <- V(new.net)$lcitations*1.5\n",
    "    return(new.net)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "2) Define smaller networks by journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "net.aer <- exclude_nodes(coauthors, 2,3,4)\n",
    "net.eca <- exclude_nodes(coauthors, 1,3,4)\n",
    "net.jpe <- exclude_nodes(coauthors, 1,2,4)\n",
    "net.qje <- exclude_nodes(coauthors, 1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "3) Create the side-by-side plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "options(repr.plot.width=15, repr.plot.height=15)\n",
    "\n",
    "par(mfrow=c(2,2), mar=c(2, 0, 2, 0), oma=c(0, 0, 0, 0))\n",
    "plot(net.aer, vertex.label=NA, layout =  layout_with_kk(net.aer))\n",
    "title(\"Coauthors Network AER\", line = 0.5) \n",
    "plot(net.eca, vertex.label=NA, layout =  layout_with_kk(net.eca))\n",
    "title(\"Coauthors Network ECA\", line = 0.5) \n",
    "plot(net.jpe, vertex.label=NA, layout =  layout_with_kk(net.jpe))\n",
    "title(\"Coauthors Network JPE\", line = 0.5) \n",
    "plot(net.qje, vertex.label=NA, layout =  layout_with_kk(net.qje))\n",
    "title(\"Coauthors Network QJE\", line = 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "4) Same process for alumni network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "net.aer.a <- exclude_nodes(alumni, 2,3,4)\n",
    "net.eca.a <- exclude_nodes(alumni, 1,3,4)\n",
    "net.jpe.a <- exclude_nodes(alumni, 1,2,4)\n",
    "net.qje.a <- exclude_nodes(alumni, 1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "options(repr.plot.width=15, repr.plot.height=15)\n",
    "par(mfrow=c(2,2), mar=c(2, 0, 2, 0), oma=c(0, 0, 0, 0))\n",
    "plot(net.aer.a, vertex.label=NA, layout =  layout_with_kk(net.aer.a))\n",
    "title(\"Alumi Network AER\", line = 0.5) \n",
    "plot(net.eca.a, vertex.label=NA, layout =  layout_with_kk(net.eca.a))\n",
    "title(\"Alumi Network ECA\", line = 0.5) \n",
    "plot(net.jpe.a, vertex.label=NA, layout =  layout_with_kk(net.jpe.a))\n",
    "title(\"Alumi Network JPE\", line = 0.5) \n",
    "plot(net.qje.a, vertex.label=NA, layout =  layout_with_kk(net.qje.a))\n",
    "title(\"Alumi Network QJE\", line = 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "**Construct Multilayer Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "  \n",
    "    \n",
    "- The previous network visualizations are all constructed with ```igraph```. The platform ```muxviz``` (http://muxviz.net/index.php), offers powerful tools to visualize and perform multilayer network analysis.\n",
    "    \n",
    "    \n",
    "    \n",
    "- MuxViz is based on R and Octave. Its installation requires local copies of R, Rtools, Octave and Java.\n",
    "    \n",
    "    \n",
    "    \n",
    "- The following is a plot of the multiplex network form by the alumni and coauthors connections.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](multilayer.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkblue\">\n",
    "    \n",
    "### 2.3 Multilayer Network Statistics Using ```muxviz``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "**Correlation Analysis:**\n",
    "    \n",
    "- Similar to what happens in standard statistics, when going from monolayer to multilayer network systems, it is relevant to calculate statistics summarizing the strength of the dependence between the network structures. Given the complexity of these objects, there are different aspects that can be consider when measuring correlation. Some important metrics are:\n",
    "    \n",
    "1. *Mean global node overlapping:* measures the fraction of node which are common to all layers (i.e., non-isolated).\n",
    "    \n",
    "2. *Mean global edge overlapping:* measures the fraction of edges which are common to all layers. \n",
    "    \n",
    "3. *Inter-layer assortativity (Pearson):* calculates the Pearson correlation coefficient between the degree of the nodes across different layers.\n",
    "\n",
    "4. *Inter-layer similarity by shortest-path distance between nodes:* calculate the shortest path between the all pairs of nodes in each layer separately. The resulting distance matrices are compared by using the Frobenius distance. \n",
    "    \n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "⚠️**Empirical Finding:**\n",
    "\n",
    "The coauthors and alumni networks present a relatively high correlation in terms of non-isolated nodes and degree similarity. The results of the mean global node overlapping and the inter-layer assortativity are 0.458 and 0.35. However, when the correlation analysis is performed based on edges in common or similar shortest paths, the resulting correlation values are low. The mean global edge overlapping and inter-layer similarity by shortest-path distance measures show correlations of 0.025 and approximately zero respectively.\n",
    "\n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    \n",
    "**Centrality Measures:**\n",
    "    \n",
    "The previous measures of centrality can be extended to the Multilayer case by considering the normalized version of \n",
    "    \n",
    "$$\\widetilde{\\mathbf{W}} = \\sum_{m=1}^{M}\\mathbf{W}_{m}$$\n",
    "    \n",
    "where $\\mathbf{W}_{m}$ is the adjacency matrix of the layer $m$. Therefore, the matrix $\\widetilde{\\mathbf{W}}$ considers all possible edges defined between two nodes in the multilayer network. \n",
    "    \n",
    "- The multiltiplexity centrality is defined as the proportion of layers in which is node is present. Because in this case we only have two layer, the multiplexity centrality is not interesting and it is excluded from the analysis.\n",
    "    \n",
    "- The following two plots show the top 5 most central articles in economics defined by degree and eigenvector centrality.\n",
    "    \n",
    "    \n",
    "⚠️**Empirical Finding:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](degree.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](eigenvector.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "**Most central articles by degree:**\n",
    "    \n",
    "- Article 538: \"Moving to Opportunity in Boston: Early Results of a Randomized Mobility Experiment\" by Lawrence F. Katz, Jeffrey R. Kling and Jeffrey B. Liebman.\n",
    "    \n",
    "    \n",
    "- Article 253: \"Vouchers for Private Schooling in Colombia: Evidence from a Randomized Natural Experiment\" by By Joshua Angrist, Eric Bettinger, Erik Bloom, Elizabeth King, Michael Kremer\n",
    "    \n",
    "    \n",
    "**Most central articles by eigenvector:**\n",
    "\n",
    "\n",
    "- Article 409: \"Information Technology, Workplace Organization, and the Demand for Skilled Labor: Firm-Level Evidence\" by Timothy F. Bresnahan, Erik Brynjolfsson and Lorin M. Hitt\n",
    "\n",
    "    \n",
    "- Article 639: \"Measuring Trust\" by Edward L. Glaeser, David I. Laibson, Jose A. Scheinkman and Christine L. Soutter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "\n",
    "**Path and distances:**\n",
    "    \n",
    "Finally, the next two plots present the mean path length and the diameter for the two layers of our empirical multilayer network (see ```pres_4``` for definitions of paths and diameters in the monolayer case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](path.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](diameter.png \"Title\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a6894f133d53440615d68604e26ec7f97a67335546363c9796937c98d80f456"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
